{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25470fb-da7a-4bab-b1fa-c5e54c6ab96a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# L2: Data Exploration for Tuning a Foundation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee94e3-0a12-4616-8a5b-cd0c78f88982",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Project environment setup:**\n",
    "\n",
    "- Load credentials and relevant Python Libraries\n",
    "- If you were running this notebook locally, you would first install Vertex AI. In this classroom, this is already installed.\n",
    "\n",
    "```\n",
    "!pip install google-cloud-aiplatform\n",
    "```\n",
    "- You can download the `requirements.txt` for this course from the workspace of this lab. `File --> Open...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d58769-1fea-4c2e-8ce1-86a8489a6e41",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53c0073-9723-40cd-8205-61a50729f5f6",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9985efad-4a9e-4fd0-b35e-569d17d8cf05",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Import the [Vertex AI](https://cloud.google.com/vertex-ai) SDK.\n",
    "- The library helps to interact with the Vertex AI services in the cloud.\n",
    "- Initialize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbb69b4-7401-4f4e-9067-86e6f5684a03",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7802ff08-ac5a-4252-a464-237ab2f86f5a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID,\n",
    "              location = REGION,\n",
    "              credentials = credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9443-b52d-4157-8b03-44774561c375",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Import [BigQuery](https://cloud.google.com/bigquery) to use as your data warehouse.\n",
    "- Initialize the client to start interacting with the data warehouse, send SQL and retrieve data into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48d8307-09a5-4518-89ea-6d46cd41353f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a99c48-ce21-4628-9bf6-ec16aeea9e51",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(project=PROJECT_ID,\n",
    "                            credentials = credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf86c4-e2e5-416f-ab57-04f53cbfa703",
   "metadata": {},
   "source": [
    "## Stack Overflow Public Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d8c159-5b14-40f1-a657-fdd451a82ddf",
   "metadata": {},
   "source": [
    "- You will use [Stack Overflow Data](https://cloud.google.com/blog/topics/public-datasets/google-bigquery-public-datasets-now-include-stack-overflow-q-a) on BigQuery Public Datasets.\n",
    "- The datasets include questions, answers and metadata related to Stack Overflow questions. Within this dataset, there are tables with data.\n",
    "- Create a SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a3e57a-8bea-44bb-891d-951d33997be9",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "QUERY_TABLES = \"\"\"\n",
    "SELECT\n",
    "  table_name\n",
    "FROM\n",
    "  `bigquery-public-data.stackoverflow.INFORMATION_SCHEMA.TABLES`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597e2d5-959e-475e-8434-b9da91c84739",
   "metadata": {},
   "source": [
    "- The query is asking to retrieve `table_name` of all the `TABLES`\n",
    "- Use the client to send your SQL and retrieve the data (tables names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca80b70a-c989-4448-b9bf-bafbadef0d17",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY_TABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3bccd0-7f04-4864-901b-402e505f341b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts_answers\n",
      "users\n",
      "posts_orphaned_tag_wiki\n",
      "posts_tag_wiki\n",
      "stackoverflow_posts\n",
      "posts_questions\n",
      "comments\n",
      "posts_tag_wiki_excerpt\n",
      "posts_wiki_placeholder\n",
      "posts_privilege_wiki\n",
      "post_history\n",
      "badges\n",
      "post_links\n",
      "tags\n",
      "votes\n",
      "posts_moderator_nomination\n"
     ]
    }
   ],
   "source": [
    "for row in query_job:\n",
    "    for value in row.values():\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861de62b-a94d-4b59-98fc-f7f027b0b13c",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4111b8f-c9ab-4b47-9a85-3430650c375c",
   "metadata": {},
   "source": [
    "- You'll fetch some data from the data warehouse and store it in Pandas dataframe for visualization.\n",
    "- Select all columns from  `posts_questions` and put the `LIMIT` as 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffec7eb-7ba4-472e-85ba-39fce6ab706f",
   "metadata": {
    "height": 147
   },
   "outputs": [],
   "source": [
    "INSPECT_QUERY = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions`\n",
    "LIMIT 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbe4aca-8d5b-4e3f-8edd-41e32fca49bf",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d974a6-d922-46ca-89fb-c29abbed0128",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_job = bq_client.query(INSPECT_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd733b-e0d9-452c-a2d9-ad4072e51c78",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Take the results of the query `-->` create an arrow table (which is part of [Apache Framework](https://arrow.apache.org/docs/index.html)) `-->` which goes into a Pandas dataframe.\n",
    "- This allows for data to be in a format which is easier to read and explore with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "491d400f-a9a4-45bf-92f7-666e2ca6bda4",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>community_owned_date</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>last_activity_date</th>\n",
       "      <th>last_edit_date</th>\n",
       "      <th>last_editor_display_name</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>owner_display_name</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73842327</td>\n",
       "      <td>Unable to start ypserv in Ubuntu</td>\n",
       "      <td>&lt;p&gt;I was trying to configure NIS master Server...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-25T05:56:32.863Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-25T05:56:32.863Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16454187</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>linux|ubuntu|linux-kernel|nis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73629682</td>\n",
       "      <td>Error Running Stable Diffusion from the comman...</td>\n",
       "      <td>&lt;p&gt;I installed Stable Diffusion v1.4 by follow...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-07T03:10:19.647Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-11T01:53:22.703Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13025866</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>python|windows|pytorch|command-line-interface</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73535922</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>&lt;p&gt;my dataframe does not contain NAN or infite...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-08-30T00:24:31.970Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-08-30T00:24:31.970Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19874740</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dataframe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  73842327                   Unable to start ypserv in Ubuntu   \n",
       "1  73629682  Error Running Stable Diffusion from the comman...   \n",
       "2  73535922  Input contains NaN, infinity or a value too la...   \n",
       "\n",
       "                                                body accepted_answer_id  \\\n",
       "0  <p>I was trying to configure NIS master Server...               None   \n",
       "1  <p>I installed Stable Diffusion v1.4 by follow...               None   \n",
       "2  <p>my dataframe does not contain NAN or infite...               None   \n",
       "\n",
       "   answer_count  comment_count community_owned_date             creation_date  \\\n",
       "0             0              0                 None  2022-09-25T05:56:32.863Z   \n",
       "1             2              0                 None  2022-09-07T03:10:19.647Z   \n",
       "2             0              0                 None  2022-08-30T00:24:31.970Z   \n",
       "\n",
       "  favorite_count        last_activity_date last_edit_date  \\\n",
       "0           None  2022-09-25T05:56:32.863Z           None   \n",
       "1           None  2022-09-11T01:53:22.703Z           None   \n",
       "2           None  2022-08-30T00:24:31.970Z           None   \n",
       "\n",
       "  last_editor_display_name last_editor_user_id owner_display_name  \\\n",
       "0                     None                None               None   \n",
       "1                     None                None               None   \n",
       "2                     None                None               None   \n",
       "\n",
       "   owner_user_id parent_id  post_type_id  score  \\\n",
       "0       16454187      None             1      0   \n",
       "1       13025866      None             1      1   \n",
       "2       19874740      None             1      0   \n",
       "\n",
       "                                            tags  view_count  \n",
       "0                  linux|ubuntu|linux-kernel|nis           1  \n",
       "1  python|windows|pytorch|command-line-interface        1281  \n",
       "2                                      dataframe           2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df = query_job\\\n",
    "    .result()\\\n",
    "    .to_arrow()\\\n",
    "    .to_pandas()\n",
    "stack_overflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1fac8-8e5e-4986-ae30-9e374ff5078b",
   "metadata": {},
   "source": [
    "### Dealing with Large Datasets\n",
    "\n",
    "- Large datasets for LLMs often don't fit into memory.\n",
    "- Select all of the columns and rows of the table `posts_questions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863e9ce6-206b-4032-8eb8-9e6204d8b158",
   "metadata": {
    "height": 130,
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY_ALL = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "632b3e00-5014-48f3-860c-895ed7b1e263",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca55b26f-1e9c-46f2-933b-0d2e85269948",
   "metadata": {
    "height": 147,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame is too large to load into memory. 403 Response too large to return. Consider specifying a destination table in your job configuration. For more details, see https://cloud.google.com/bigquery/troubleshooting-errors\n",
      "\n",
      "Location: US\n",
      "Job ID: bab352e9-485c-4db1-9605-d047f11ec87e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    stack_overflow_df = query_job\\\n",
    "    .result()\\\n",
    "    .to_arrow()\\\n",
    "    .to_pandas()\n",
    "except Exception as e:\n",
    "    print('The DataFrame is too large to load into memory.', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999ff41-e115-4491-84c3-9d7f04fafd85",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** The data is too large to return, as it is not fitting into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406553f-c356-4dc8-a119-7d8f02787d4b",
   "metadata": {},
   "source": [
    "#### Joining Tables and Query Optimization\n",
    "\n",
    "- When working with (large) data, query optimizing is needed in order to save time and resources.\n",
    "- Select questions as `input_text` (column 1), answers as `output_text` (column 2).\n",
    "- Take the questions from `posts_questions` and answers from `posts_answers`.\n",
    "- Join the questions and their corresponding accepted answers based on their same `unique ID`.\n",
    "- Making sure the question is about `Python`, and that it `has an answer`. And the date the question was posted is on or after `2020-01-01`\n",
    "- Limit as 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71dc0eb0-ca3d-4d29-ae7e-f3b40cab9184",
   "metadata": {
    "height": 317,
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT\n",
    "    CONCAT(q.title, q.body) as input_text,\n",
    "    a.body AS output_text\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "JOIN\n",
    "    `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "ON\n",
    "    q.accepted_answer_id = a.id\n",
    "WHERE\n",
    "    q.accepted_answer_id IS NOT NULL AND\n",
    "    REGEXP_CONTAINS(q.tags, \"python\") AND\n",
    "    a.creation_date >= \"2020-01-01\"\n",
    "LIMIT\n",
    "    10000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8affe03b-6be6-4be0-ad09-703f47dc31b9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_job = bq_client.query(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d23c0df2-2365-4a49-9dee-f49c800312dd",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is there a way to check if a rect intersects a...</td>\n",
       "      <td>&lt;p&gt;You can simply compare the x and y values o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creating jira customfield issue&lt;p&gt;Does anyone ...</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;issue = JIRA_INTERFACE.create_issue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  Is there a way to check if a rect intersects a...   \n",
       "1  creating jira customfield issue<p>Does anyone ...   \n",
       "\n",
       "                                         output_text  \n",
       "0  <p>You can simply compare the x and y values o...  \n",
       "1  <pre><code>issue = JIRA_INTERFACE.create_issue...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### this may take some seconds to run\n",
    "stack_overflow_df = query_job.result()\\\n",
    "                        .to_arrow()\\\n",
    "                        .to_pandas()\n",
    "\n",
    "stack_overflow_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bdc676-a15d-4d28-a95c-7b451c6427b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adding Instructions\n",
    "\n",
    "- Instructions for LLMs have been shown to improve\n",
    "model performance and generalization to unseen tasks [(Google, 2022)](https://arxiv.org/pdf/2210.11416.pdf).\n",
    "- Wihtout the instruction, it is only question and answer. Model might not understand what to do.\n",
    "- With the instructions, the model gets a guideline as to what task to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66208ed7-7325-4613-8b57-fedfa9c85aef",
   "metadata": {
    "height": 130,
    "tags": []
   },
   "outputs": [],
   "source": [
    "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
    "Please answer the following Stackoverflow question on Python. \\\n",
    "Answer it like you are a developer answering Stackoverflow questions.\n",
    "\n",
    "Stackoverflow question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645069aa-7e45-4fa3-91e4-665b9f7c17a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "- A new column will combine `INSTRUCTION_TEMPLATE` and the question `input_text`.\n",
    "- This avoids overwritting of any existing column which might be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed30a78b-6b4a-4b07-b66f-b5147e6ec062",
   "metadata": {
    "height": 62,
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack_overflow_df['input_text_instruct'] = INSTRUCTION_TEMPLATE + ' '\\\n",
    "    + stack_overflow_df['input_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f22f9-cb41-4035-842e-bd6b27c01bf4",
   "metadata": {},
   "source": [
    "### Dataset for Tuning\n",
    "\n",
    "- Divide the data into a training and evaluation. By default, 80/20 split is used.\n",
    "- This (80/20 split) allows for more data to be used for tuning. The evaluation split is used as unseen data during tuning to evaluate performance.\n",
    "- The `random_state` parameter is used to ensure random sampling for a fair comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dc2940f-735a-4fe0-b579-b8e63d161d57",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6c97888-7eb8-49f0-b3e7-2a417d931b49",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "train, evaluation = train_test_split(\n",
    "    stack_overflow_df,\n",
    "    ### test_size=0.2 means 20% for evaluation\n",
    "    ### which then makes train set to be of 80%\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb841d8-e71a-464c-8cb3-3c712a16dc6a",
   "metadata": {},
   "source": [
    "#### Different Datasets and Flow\n",
    "\n",
    "- Versioning data is important.\n",
    "- It allows for reproducibility, traceability, and maintainability of machine learning models.\n",
    "- Get the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0b0f876-10bf-4dbf-ae0f-1f90d62cb72c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf919020-de23-4e02-895f-3cf22fe75f91",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989a1ea-1bdb-4e43-a4c1-fec76812c26d",
   "metadata": {},
   "source": [
    "- Generate a `jsonl` file.\n",
    "- Name it as `tune_data_stack_overflow_python_qa-{date}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7427ff3f-6f3a-4053-982c-3aa1fcfb656a",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['input_text_instruct'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_text_instruct\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m tune_jsonl \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['input_text_instruct'] not in index\""
     ]
    }
   ],
   "source": [
    "cols = ['input_text_instruct','output_text']\n",
    "tune_jsonl = train[cols].to_json(orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6727f808-a216-45e3-8073-4545e23c796d",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "training_data_filename = f\"tune_data_stack_overflow_\\\n",
    "                            python_qa-{date}.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f639359-f873-404f-9fd7-bf88db8c52a0",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(training_data_filename, \"w\") as f:\n",
    "    f.write(tune_jsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44daae92-2502-4913-a53f-7dee952797fe",
   "metadata": {},
   "source": [
    "## Try it Yourself! - Evaluation Set\n",
    "\n",
    "The code above generted a `jsonl` file for the `train` set. Now, its time for you to make the `evaluation` set, which you can name as `tune_eval_data_stack_overflow_python_qa-{date}.jsonl`. The code for that is also provided to you in the drop down below, but we encourage you to try it yourself first before you look at it.\n",
    "\n",
    "<details>\n",
    "  <summary><font size=\"2\" color=\"darkgreen\"><b>Code for Evaluation Set (Click to expand)</b></font></summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "cols = ['input_text_instruct','output_text']\n",
    "### you need to use the \"evaluation\" set now\n",
    "tune_jsonl = evaluation[cols].to_json(orient=\"records\", lines=True)\n",
    "\n",
    "### change the file name\n",
    "### use \"tune_eval_data_stack_overflow_python_qa-{date}.jsonl\"\n",
    "evaluation_data_filename = f\"tune_eval_data_stack_overflow_\\\n",
    "                            python_qa-{date}.jsonl\"\n",
    "\n",
    "### write the file\n",
    "with open(evaluation_data_filename, \"w\") as f:\n",
    "    f.write(tune_jsonl)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92813bc1-1a68-473d-be14-d5ee480faedc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b9e97-5f4f-49ae-ba3f-d130dbb6674b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
